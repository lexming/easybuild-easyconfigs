# This file is an EasyBuild reciPY as per https://github.com/easybuilders/easybuild
# Author: Denis Kristak
easyblock = 'PythonBundle'

name = 'jax'
version = '0.2.22'
versionsuffix = '-CUDA-%(cudaver)s-noavx'

homepage = 'https://pypi.python.org/pypi/jax'
description = """Composable transformations of Python+NumPy programs:
differentiate, vectorize, JIT to GPU/TPU, and more"""

toolchain = {'name': 'foss', 'version': '2021a'}
toolchainopts = {'extra_cxxflags': '-mno-avx512f'}

builddependencies = [
    ('Bazel', '3.7.2'),
    ('pytest-xdist', '2.3.0'),
    # git 2.x required to fetch repository 'io_bazel_rules_docker'
    ('git', '2.32.0', '-nodocs'),
]

dependencies = [
    ('CUDA', '11.3.1', '', True),
    ('cuDNN', '8.2.1.32', '-CUDA-%(cudaver)s', True),
    ('NCCL', '2.10.3', '-CUDA-%(cudaver)s'),
    ('Python', '3.9.5'),
    ('SciPy-bundle', '2021.05'),
    ('flatbuffers-python', '2.0'),
]

# running the tests with lots of cores results in test failures because not enough threads can be started,
# and running with a single core also results in systematic test failures
# 4 cores seems to work best
parallel = 4

# downloading TensorFlow tarball to avoid that Bazel downloads it during the build
# note: this *must* be the exact same commit as used in jaxlib-*/WORKSPACE
local_tf_commit = '3a7587c9ff5cd365643b6fbc1b7c20c8c97e0976'
local_tf_dir = 'tensorflow-%s' % local_tf_commit
local_tf_builddir = '%(builddir)s/' + local_tf_dir

local_jax_prebuildopts = "sed -i 's$pathToSed$%s$g' WORKSPACE && " % local_tf_builddir

use_pip = True

default_easyblock = 'PythonPackage'
default_component_specs = {
    'sources': [SOURCE_TAR_GZ],
    'source_urls': [PYPI_SOURCE],
    'start_dir': '%(name)s-%(version)s',
    'use_pip': True,
    'sanity_pip_check': True,
    'download_dep_fail': True,
}

components = [
    ('absl-py', '0.14.1', {
        'options': {'modulename': 'absl'},
        'checksums': ['eb0383bd431c0d7b2320179904cab00120a10977e3c9671d99efbbed17efb55a'],
    }),
    ('jaxlib', '0.1.72', {
        'sources': [
            '%(name)s-v%(version)s.tar.gz',
            {
                'download_filename': '%s.tar.gz' % local_tf_commit,
                'filename': 'tensorflow-%s.tar.gz' % local_tf_commit,
            }
        ],
        'source_urls': [
            'https://github.com/google/jax/archive/',
            'https://github.com/tensorflow/tensorflow/archive/'
        ],
        'patches': [
            'jaxlib-0.1.70_add-bazel-args-to-shutdown.patch',
            'jaxlib-0.1.72_no-tensorflow-download.patch',
            ('TensorFlow-2.7.0_use-noncanonical-include-paths-cuda.patch', '../' + local_tf_dir),
            #('TensorFlow-2.7.0_add-binutils-prefix.patch', '../' + local_tf_dir),
        ],
        'checksums': [
            # jaxlib-v0.1.72.tar.gz
            '49dee44cb7f2e49500d25cefceea28bfffb1f5f62e78684dfd7b71892ca4293a',
            # tensorflow-3a7587c9ff5cd365643b6fbc1b7c20c8c97e0976.tar.gz
            '012c5ed99c7369a967eecad89c06a31663255e5307e407f8b625457e7c137781',
            # jaxlib-0.1.70_add-bazel-args-to-shutdown.patch
            'c0ea6abd7827d3c37bdd60c30c7b0613fc86b91274c6a1a4cf13a3c7f9ce7631',
            # jaxlib-0.1.72_no-tensorflow-download.patch
            '489897f57fed3c2e7d425ecd7fa38abec4f8267c89769082c758009266aaa106',
            # TensorFlow-2.7.0_add-binutils-prefix.patch
            #'a3033ccf13d8dc757ea12ef51678525ab4fc3cace5e5eeab2e79e4a53332dcd6',
            # TensorFlow-2.7.0_use-noncanonical-include-paths-cuda.patch
            '0a759010c253d49755955cd5f028e75de4a4c447dcc8f5a0d9f47cce6881a9db',
        ],
        'start_dir': 'jax-jaxlib-v%(version)s',
        'prebuildopts': local_jax_prebuildopts,
    }),
]

exts_list = [
    ('opt_einsum', '3.3.0', {
        'checksums': ['59f6475f77bbc37dcf7cd748519c0ec60722e91e63ca114e68821c0c54a46549'],
    }),
    (name, version, {
        'source_tmpl': '%(name)s-v%(version)s.tar.gz',
        'source_urls': ['https://github.com/google/jax/archive/'],
        'patches': [
            'jax-0.2.19_fix-update-of-cache-access-time.patch',
        ],
        'checksums': [
            '925c00e2f976bfc6b522ff27556823d8a56b117d45bcf2d21cd6929beb50245a',  # jax-v0.2.22.tar.gz
            # jax-0.2.19_increase-cache-test-sleep-time.patch
            'e20562f67d63cc7e3478f7a92940291b2c8e328d605426bbabf89d8c2e1dd806',
        ],
        # deliberately not testing in parallel, as that results in (additional) failing tests;
        # use XLA_PYTHON_CLIENT_ALLOCATOR=platform when running GPU tests in parallel,
        # to avoid each test fully allocating the GPU memory...,
        # see https://github.com/google/jax/issues/7323 and
        # https://github.com/google/jax/blob/main/docs/gpu_memory_allocation.rst;
        # use CUDA_VISIBLE_DEVICES=0 to avoid failing tests on systems with multiple GPUs;
        'runtest': 'CUDA_VISIBLE_DEVICES=0 JAX_ENABLE_X64=true TF_DISABLE_MKL=1 pytest tests',
    }),
]

sanity_pip_check = True

moduleclass = 'tools'
